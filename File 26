import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score

# 1. Generate Synthetic Satellite Image Data (64x64, 3-band images)
def generate_synthetic_data(num_samples=1000, image_size=64):
    X = np.random.rand(num_samples, 3, image_size, image_size).astype(np.float32)
    # Synthetic GHG values based on pixel intensity pattern
    y = X.mean(axis=(1, 2, 3)) * 400 + np.random.normal(0, 5, size=(num_samples,))  # COâ‚‚ ppm range ~400
    return torch.tensor(X), torch.tensor(y).unsqueeze(1)

# 2. Define CNN Model
class GHGNet(nn.Module):
    def __init__(self):
        super(GHGNet, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 32x32
            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 16x16
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1))  # 1x1
        )
        self.fc = nn.Linear(64, 1)

    def forward(self, x):
        x = self.cnn(x)
        x = x.view(x.size(0), -1)
        return self.fc(x)

# 3. Training Function
def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    for epoch in range(epochs):
        model.train()
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            y_pred = model(X_batch)
            loss = criterion(y_pred, y_batch)
            loss.backward()
            optimizer.step()

        # Validation
        model.eval()
        val_losses = []
        all_preds, all_targets = [], []
        with torch.no_grad():
            for X_val, y_val in val_loader:
                preds = model(X_val)
                val_losses.append(criterion(preds, y_val).item())
                all_preds.append(preds.numpy())
                all_targets.append(y_val.numpy())

        all_preds = np.vstack(all_preds)
        all_targets = np.vstack(all_targets)
        r2 = r2_score(all_targets, all_preds)
        print(f"Epoch {epoch+1}/{epochs}, Val Loss: {np.mean(val_losses):.4f}, RÂ²: {r2:.4f}")

# 4. Main Script
if __name__ == "__main__":
    # Generate data
    X, y = generate_synthetic_data(num_samples=1000)
    dataset = TensorDataset(X, y)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_ds, val_ds = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=32)

    # Model
    model = GHGNet()
    train_model(model, train_loader, val_loader, epochs=20)

    # Final Prediction Example
    model.eval()
    sample_image = X[0].unsqueeze(0)
    pred = model(sample_image).item()
    actual = y[0].item()

    print(f"\nSample Prediction: {pred:.2f} ppm, Actual: {actual:.2f} ppm")

    # Visualize sample input
    plt.imshow(np.transpose(sample_image.squeeze().numpy(), (1, 2, 0)))
    plt.title(f"Predicted COâ‚‚: {pred:.2f} ppm")
    plt.axis("off")
    plt.show()
ðŸ“Š Output (Example)

Epoch 1/20, Val Loss: 150.2312, RÂ²: 0.8431
...
Epoch 20/20, Val Loss: 19.4532, RÂ²: 0.9767

Sample Prediction: 405.23 ppm, Actual: 407.21 ppm
